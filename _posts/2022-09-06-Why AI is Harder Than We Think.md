---
layout: post
title: Why AI is Harder Than We Think?
summary: "why ai is hard bro"
cover: "https://www.popsci.com/uploads/2019/03/18/EHFCKIHXJQ4QAQHLRRLRPAZ6SQ.jpg?auto=webp"
tags: ["paper review", "news"]
---

> First of all, this blog post is inspired by the paper “Why AI is Harder Than We Think?” whose author is [Melanie Mitchell](https://www.santafe.edu/people/profile/melanie-mitchell) who is a Professor at the Santa Fe University and Mitchell has numerous researches on artificial intelligence and cognitive science. I really encourage you to read the [original paper](https://arxiv.org/abs/2104.12871).

Today, we all know that Artificial Intelligence is a popular topic in both academic researches and the society. This popularity is affecting expectations of AI and future of it. Mainly, these situations occur because of some terminological fallacies and misinterpretation of the “General AI”. In the history of AI, the technology and new initiatives hyped the field of AI and the following investments by governments and startups supported that. But the expectations are stucked in two cycling periods, “AI Spring” and “AI Winter.

## AI Spring and AI Winter

The AI Spring can be described as the hoping period of AI, new approaches have come up and ideas of where the AI can go and which problems it can solve are debated in a positive attitude. Conversely, the AI Winter follows the spring when all the pretentious expectations could not happen and AI lose its confidence.

Lots of innovations have been made by researchers and technology companies throughout time. These innovations are started with perceptron theorem in 1958 and expert systems, machine learning and deep learning followed it after each AI Winters. But still, current situation of AI is far from generalization and learning different from the human-like learning. Today’s AI systems are just modified to achieve a specific task but the understanding of it by everyone is pretty different and developments are assumed as a general intelligence that can act like a human and do what a human does. There are couple of fallacies that people commonly fall in.

The first fallacy can be named as believing every development is a step through the general intelligence. Of course, every improvement or achievement lets AI to handle another task or existing one more accurately but it still cannot be predicted encountering with an unfortunate obstacle through the way of glorious general AI. That fallacy makes us expect more after every development.

The second fallacy is related with the Moravec’s Paradox which states that easy things that a human can do is actually harder for AI and same goes for hard tasks. This is because the unconscious intelligence and complexity of human thought. Therefore, simple thinking processes are harder to be accomplished by AI since we cannot reason about these tasks.

The third fallacy is misusing or misinterpreting of terminology that is used about AI. More basically it is about using same words for human actions and AI capabilities. About a common term, when we use learning for an AI most of the people assume that as a human-like learning process, however it is far different from that and based on some mathematical optimizations. These complexities lead by media or some researches and enables societies and even some researches to misinterpret the results of the AI.

The fourth and last fallacy is associating the phenomenon of intelligence with human brain not whole-body interactions. While interpreting human intelligence and AI together only human brain and its acts are considered even the interaction of human body with the nature is known. Forgetting all the emotions and interactions with environment can misled AI to understand the world and can be devastating.

To conclude, I believe that while interpreting results of AI, researches and developments should be done in a scientific sense while considering psychology of human and philosophy of AI.
