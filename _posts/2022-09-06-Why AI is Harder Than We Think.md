---
layout: post
title: Why AI is Harder Than We Think?
summary: "why ai is hard bro"
cover: "https://www.popsci.com/uploads/2019/03/18/EHFCKIHXJQ4QAQHLRRLRPAZ6SQ.jpg?auto=webp"
tags: ["paper review", "news"]
---

> First of all, this blog post is inspired by the paper “Why AI is Harder Than We Think?” whose author is [Melanie Mitchell](https://www.santafe.edu/people/profile/melanie-mitchell){:target="_blank"} who is a Professor at the Santa Fe University and has numerous researches on artificial intelligence and cognitive science. Mitchell has pointed out four fallacies while interpretting the AI and I really encourage you to read the [original paper](https://arxiv.org/abs/2104.12871){:target="_blank"}.

Today, we all know that Artificial Intelligence is a popular topic in both academic researches and the society. This popularity is affecting expectations of AI and future of it and with the improvements in the field, it is expected that a rapid progress towards "General AI" by first the researchers then the society. Theoretically, General AI, in other terms [Artificial General Intelligence (AGI)](https://en.wikipedia.org/wiki/Artificial_general_intelligence){:target="_blank"}, is the use of artificial intelligence in any domain to solve any challenge that calls for intelligence by behaving like a person.

However, Mitchell states that *"Even with today’s seemingly fast pace of AI breakthroughs, the development of long-promised technologies such as self-driving cars, housekeeping robots, and conversational companions has turned out to be much harder than many people expected."* and these situations occur because of people's over-confidence about AI, terminological fallacies while interpreting it and our perception about the intelligence.

Related with those fallacies and misinterpretations, AI expert Drew McDermott talks about a **cyclical pattern** in the field of AI. As we can see in the history of AI, it means that the technology and new initiatives hyped the field of AI and the following investments by governments and startups supported that. But the expectations are stucked in two cycling periods, "AI Spring" and "AI Winter".

![Spring and Winter period of AI](/assets/img/why_ai_is_harder_than_we_think/ai_winter.webp)

## AI Spring and AI Winter

The AI Spring can be described as the hoping period of AI, new approaches have come up and ideas of where the AI can go and which problems it can solve are debated in a positive attitude. Conversely, the AI Winter follows the spring when all the pretentious expectations could not happen and AI lose its confidence.

Lots of innovations have been made by researchers and technology companies throughout time. These innovations started with the perceptron theorem in 1958 and optimistic pictures of the [Symbolic AI](http://wiki.pathmind.com/symbolic-reasoning){:target="_blank"}, which is simply an AI system acting like the human brain with defined rules against symbols and abstract concepts, produced by the AI practitioners. But these perceptron models are very limited and the first *AI Winter* appeared after that optimism, the fundings have been disappeared. In early 80s, AI cathed a hype again with "expert systems" such as Japan's "Fifth Generation" project and US's "Strategic Computing Initiative". Expert systems relied on humans to create rules, therefore that kind of a system was unable to generalized towards various domains. As expected, all the fundings decreased again.

About the time after that winter, Mitchell gives an anecdote as;
>"Indeed, the late 1980’s marked the beginning of a new AI winter, and the field’s reputation suffered. When I received my PhD in 1990, I was advised not to use the term “artificial intelligence” on my job applications."

After all those winters, the 



Perceptron model - perceptrons very limited, funding decrease
Expert systems, japan fifth generation, US strategic computing - lack of generality
Machine learning, predictive models, deep learning is possible now

Then true AI and general AI and human-level AI is rised
Deep learning is vulnerable against adversarial attacks
"It’s still a matter of debate in the AI community whether such understanding can be achieved by adding network layers and more training data, or whether something more fundamental is missing."

There are new DL approaches generating optimism about AI, SSL

"While these fallacies are well-known in the AI community, many assumptions made by experts still fall victim to these fallacies, and give us a false sense of confidence about the near-term prospects of "truly" intelligent machines."


Lots of innovations have been made by researchers and technology companies throughout time. These innovations are started with perceptron theorem in 1958 and expert systems, machine learning and deep learning followed it after each AI Winters. But still, current situation of AI is far from generalization and learning different from the human-like learning. Today’s AI systems are just modified to achieve a specific task but the understanding of it by everyone is pretty different and developments are assumed as a general intelligence that can act like a human and do what a human does. There are couple of fallacies that people commonly fall in.

## Fallacy 1: Narrow intelligence is on a continuum with general intelligence

The first fallacy can be named as believing every development is a step through the general intelligence. Of course, every improvement or achievement lets AI to handle another task or existing one more accurately but it still cannot be predicted encountering with an unfortunate obstacle through the way of glorious general AI. That fallacy makes us expect more after every development.

## Fallacy 2: Easy things are easy and hard things are hard

The second fallacy is related with the Moravec’s Paradox which states that easy things that a human can do is actually harder for AI and same goes for hard tasks. This is because the unconscious intelligence and complexity of human thought. Therefore, simple thinking processes are harder to be accomplished by AI since we cannot reason about these tasks.

## Fallacy 3: The lure of wishful mnemonics

The third fallacy is misusing or misinterpreting of terminology that is used about AI. More basically it is about using same words for human actions and AI capabilities. About a common term, when we use learning for an AI most of the people assume that as a human-like learning process, however it is far different from that and based on some mathematical optimizations. These complexities lead by media or some researches and enables societies and even some researches to misinterpret the results of the AI.

## Fallacy 4: Intelligence is all in the brain

The fourth and last fallacy is associating the phenomenon of intelligence with human brain not whole-body interactions. While interpreting human intelligence and AI together only human brain and its acts are considered even the interaction of human body with the nature is known. Forgetting all the emotions and interactions with environment can misled AI to understand the world and can be devastating.

To conclude, I believe that while interpreting results of AI, researches and developments should be done in a scientific sense while considering psychology of human and philosophy of AI.
